{"CVE Code": "CVE-2017-14158", "Description": "Scrapy 1.4 allows remote attackers to cause a denial of service (memory consumption) via large files because arbitrarily many files are read into memory, which is especially problematic if the files are then individually written in a separate thread to a slow storage resource, as demonstrated by interaction between dataReceived (in core/downloader/handlers/http11.py) and S3FilesStore.", "NVD Link": "https://nvd.nist.gov/vuln/detail/CVE-2017-14158", "Vulnerability Categories": "Denial of service", "Affected Products": "\nScrapy\u00bbScrapy\u00bbVersion:1.4cpe:2.3:a:scrapy:scrapy:1.4:*:*:*:*:*:*:*Matching versions", "EPSS Score": "0.15% Probability of exploitation activity in the next 30 days\n~ 51 % Percentile, the proportion of vulnerabilities that are scored at or less", "EPSS History": "\n #  Date  Old EPSS Score  New EPSS Score  Delta (New - Old) \n 1  2024-12-17  0.24%  0.15%  -0.09 \n 2  2023-07-16  0.22%  0.24%  +0.02 \n 3  2023-03-07  1.06%  0.22%  -0.84 ", "CVSS Scores": "7.8", "CWE": [{"CWE_ID": "CWE-400 Uncontrolled Resource Consumption", "CWE_link": "/cwe-details/400/Uncontrolled-Resource-Consumption.html"}], "Reference": [{"ref_link": "http://blog.csdn.net/wangtua/article/details/75228728", "ref_desc": "Exploit;Third Party Advisory", "ref_cve_link": "N/A"}, {"ref_link": "https://github.com/scrapy/scrapy/issues/482", "ref_desc": "S3FilesStore can use a lot of memory \u00b7 Issue #482 \u00b7 scrapy/scrapy \u00b7 GitHubIssue Tracking;Third Party Advisory", "ref_cve_link": "N/A"}]}